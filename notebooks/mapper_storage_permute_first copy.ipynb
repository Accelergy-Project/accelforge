{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 16:35:02 INFO        Loading yaml file architecture/four_level.arch.yaml\n",
      "2025-05-12 16:35:02 INFO        Found top key variables in architecture/four_level.arch.yaml\n",
      "2025-05-12 16:35:02 INFO        Found top key architecture in architecture/four_level.arch.yaml\n",
      "2025-05-12 16:35:02 INFO        Found top key compound_components in architecture/four_level.arch.yaml\n",
      "2025-05-12 16:35:02 INFO        Loading yaml file workloads/mha_full_new.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key workload in workloads/mha_full_new.yaml\n",
      "2025-05-12 16:35:03 INFO        Loading yaml file workloads/mha_full_new.renames.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key renames in workloads/mha_full_new.renames.yaml\n",
      "2025-05-12 16:35:03 WARNING     Loading configuration file from /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Loading yaml file /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key version in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key environment_variables in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key expression_custom_functions in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Found top key component_plug_ins in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:03 INFO        Running processor References2CopiesProcessor\n",
      "2025-05-12 16:35:03 INFO        Processor References2CopiesProcessor done after 0.02 seconds\n",
      "2025-05-12 16:35:03 INFO        Specification processed in 0.02 seconds\n",
      "2025-05-12 16:35:04 WARNING     Loading configuration file from /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Loading yaml file /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Found top key version in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Found top key environment_variables in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Found top key expression_custom_functions in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Found top key component_plug_ins in /root/.config/fastfusion/config.yaml\n",
      "2025-05-12 16:35:04 INFO        Specification processed in 0.00 seconds\n",
      "2025-05-12 16:35:04 INFO        Calculated Specification[variables].Variables[version] as \"0.5\" = 0.5.\n",
      "2025-05-12 16:35:04 INFO        Calculated Specification[architecture].Architecture[nodes].ArchNodes[0].Storage(MainMemory)[attributes].StorageAttributes[energy_scale] as \"(450 / 64) / 8\" = 0.87890625.\n",
      "2025-05-12 16:35:04 INFO        Calculated Specification[architecture].Architecture[nodes].ArchNodes[1].Storage(GlobalBuffer)[attributes].StorageAttributes[size] as \"1024*1024*128*8\" = 1073741824.\n",
      "2025-05-12 16:35:04 INFO        Calculated Specification[architecture].Architecture[nodes].ArchNodes[2].Storage(LocalBuffer)[attributes].StorageAttributes[size] as \"1024*1024*32*8\" = 268435456.\n",
      "2025-05-12 16:35:04 INFO        Specification processed in 0.00 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mappings: 0\n",
      "0/48: {'Register': {WK}, 'LocalBuffer': {K}, 'GlobalBuffer': {K}, 'MainMemory': {I, WK}}\n",
      "\t[{(I, 'MainMemory'), (WK, 'MainMemory')}, { }, {(K, 'GlobalBuffer')}, { b, d, e, h, mX}, { }, {(K, 'LocalBuffer')}, { b, d, e, h, mX}, { b, d, e, h, mY}, { d}, {(WK, 'Register')}, { b, m}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import itertools\n",
    "from typing import Union\n",
    "from fastfusion.frontend._set_parse import InvertibleSet\n",
    "from fastfusion.frontend.arch import Leaf, Storage\n",
    "from fastfusion.frontend.workload.workload_spec import RankVariable, Tensor\n",
    "from fastfusion import Specification\n",
    "\n",
    "# # Example mapping node\n",
    "# type: \"temporal\"\n",
    "# rank: P\n",
    "# # Choose one of the following cases\n",
    "# # Case 1.a\n",
    "# tile_shape: 3   # will make tile shapes with shape 3\n",
    "# # Case 1.b\n",
    "# tile_shape: null # will create a sympy symbol to represent tile shape and use that\n",
    "# # Case 2.a\n",
    "# factor: 3       # will make 3 as evenly shaped possible tiles\n",
    "# # Case 2.b\n",
    "# factor: null    # will create a sympy symbol to represent the factor, then same as 2.a\n",
    "# # Case 3   (I'm only showing null from now on)\n",
    "# tile_pattern:\n",
    "#   stride: null\n",
    "#   initial_shape: null  # This will create tile like this [0, 1, ..., initial_shape - 1], [initial_shape, ..., initial_shape + stride - 1], [initial_shape + stride, ..., initial_shape + 2*stride - 1], ...\n",
    "# # Case 4\n",
    "# tile_pattern:\n",
    "#   stride: null\n",
    "#   shape: null      # This will create tile like this [0, 1, ..., shape-1], [stride, stride+1, ..., stride + shape-1], [2*stride, 2*stride + 1, ..., 2*stride + shape - 1], ...\n",
    "\n",
    "#         choices = list(integer_factorizations_to_n_parts(rank_size, len(loops)))\n",
    "\n",
    "# Tile shape constraint: Applies to all tensor(s) in a storage node for which that tile shape is relevant\n",
    "# Loop bound constraint: Only for spatial\n",
    "\n",
    "spec = Specification.from_yaml(\n",
    "    \"architecture/four_level.arch.yaml\",\n",
    "    \"workloads/mha_full_new.yaml\",\n",
    "    \"workloads/mha_full_new.renames.yaml\",\n",
    ")\n",
    "workload = spec.workload\n",
    "renames = spec.renames\n",
    "\n",
    "einsum_name = \"K\"\n",
    "einsum = workload.einsums[einsum_name]\n",
    "rank_variables = einsum.rank_variables\n",
    "tensors = einsum.tensors\n",
    "symbol_table = workload.get_constraint_symbol_table(einsum_name, renames)\n",
    "first_value = next(iter(symbol_table.values()))\n",
    "arch_nodes = spec.get_flattened_architecture()\n",
    "tensor2rank_variables = einsum.tensor2rank_variables\n",
    "storage_order = [n.name for n in arch_nodes if isinstance(n, Storage)]\n",
    "rank_variable_to_size = {r: 16 for r in rank_variables}\n",
    "\n",
    "from itertools import chain, combinations\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))\n",
    "        \n",
    "def make_storage_choices_one_level(node: Leaf, symbol_table: dict[str, InvertibleSet]):\n",
    "    if not isinstance(node, Storage):\n",
    "        yield set(), symbol_table\n",
    "        return\n",
    "    new_symbol_table = copy.copy(symbol_table)\n",
    "    storage_constraints = node.constraints.storage._parse_keep_bypass(symbol_table)\n",
    "    must_keep = first_value.to_my_space(storage_constraints[\"keep\"])\n",
    "    must_bypass = first_value.to_my_space(storage_constraints[\"bypass\"])\n",
    "\n",
    "    if must_keep - new_symbol_table[\"All\"]:\n",
    "        raise KeyError(f\"Keep constraint for {node.name} includes tensors that are not in the einsum: {must_keep - new_symbol_table['All']}\")\n",
    "    if must_bypass - new_symbol_table[\"All\"]:\n",
    "        raise KeyError(f\"Bypass constraint for {node.name} includes tensors that are not in the einsum: {must_bypass - tensors}\")\n",
    "    if must_keep & must_bypass:\n",
    "        raise KeyError(f\"Keep and bypass constraints for {node.name} intersect: {must_keep & must_bypass}\")\n",
    "    \n",
    "    may_keep = tensors - must_bypass - must_keep\n",
    "\n",
    "    for subset in powerset(may_keep):\n",
    "        subset = first_value.to_my_space(set(subset))\n",
    "        keep_choice = first_value.to_my_space(subset | must_keep)\n",
    "        keep_choice.tensors = lambda: keep_choice # So users can do MainMemory().tensors(). Optional.\n",
    "        new_symbol_table[node.name] = keep_choice\n",
    "        assert not any(isinstance(k, str) for k in keep_choice)\n",
    "        keep_choice = keep_choice.to_my_space({copy.copy(t) for t in keep_choice})\n",
    "        for t in keep_choice:\n",
    "            t._storage_name = node.name\n",
    "            t._required = t in must_keep\n",
    "            t._uneven = node.constraints.storage.uneven\n",
    "        yield keep_choice, new_symbol_table\n",
    "\n",
    "def make_storage_choices_all_levels(nodes: list[Storage], symbol_table: dict[str, InvertibleSet]):\n",
    "    while nodes and not isinstance(nodes[0], Storage):\n",
    "        nodes = nodes[1:]\n",
    "    if len(nodes) == 0:\n",
    "        yield dict(), symbol_table\n",
    "        return\n",
    "\n",
    "    for choice, symbol_table in make_storage_choices_one_level(nodes[0], symbol_table):\n",
    "        for subchoices, symbol_table in make_storage_choices_all_levels(nodes[1:], symbol_table):\n",
    "            yield {**subchoices, nodes[0].name: choice}, symbol_table\n",
    "\n",
    "def enumerate_rank_variable_sets(mapping: list[str]) -> list[tuple[int, \"RankVariableSet\"]]:\n",
    "    return [(i, r) for i, r in enumerate(mapping) if isinstance(r, RankVariableSet)]\n",
    "\n",
    "def enumerate_tensor_sets(mapping: list[str]) -> list[tuple[int, \"TensorSet\"]]:\n",
    "    return [(i, t) for i, t in enumerate(mapping) if isinstance(t, TensorSet)]\n",
    "\n",
    "class TensorSet(set):\n",
    "    def __str__(self):\n",
    "        return f\"{{{', '.join(str(t) for t in sorted(self))}}}\"\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "    def tensors(self) -> list[Tensor]:\n",
    "        return [t[0] for t in self]\n",
    "\n",
    "class RankVariableSet(set):\n",
    "    def __init__(self, *args, spatial=None, spatial_node=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.spatial = spatial\n",
    "        self.spatial_node = spatial_node\n",
    "    \n",
    "    def __str__(self):\n",
    "        prefix = f\"{self.spatial_node}\" if self.spatial_node else \"\"\n",
    "        postfix = f\"{self.spatial}\" if self.spatial else \"\"\n",
    "        return f\"{{ {', '.join(str(t) for t in sorted(self))}{postfix}}}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "    \n",
    "def valid_storage_order(mapping: list[str]):\n",
    "    for i in range(len(mapping)):\n",
    "        for j in range(i, len(mapping)):\n",
    "            for t1, t2 in itertools.product(mapping[i].tensors(), mapping[j].tensors()):\n",
    "                if t1.name != t2.name:\n",
    "                    continue\n",
    "                \n",
    "                s1, s2 = t1._storage_name, t2._storage_name\n",
    "                s1_idx, s2_idx = storage_order.index(s1), storage_order.index(s2)\n",
    "\n",
    "                # If a tensor is stored in two levels back-to-back, then we\n",
    "                # should have bypassed the outer storage if possible.\n",
    "                if i == j or i == j - 1:\n",
    "                    if s1_idx < s2_idx and not t1._required:\n",
    "                        return False\n",
    "                    if s2_idx < s1_idx and not t2._required:\n",
    "                        return False\n",
    "                    \n",
    "                # Ensure order\n",
    "                if i < j and s2_idx < s1_idx:\n",
    "                    return False\n",
    "    return True\n",
    "            \n",
    "def recursive_order_storage_choices(\n",
    "    mapping: list[str],\n",
    "    nodes: list[Storage],\n",
    "    remaining_choices: list,\n",
    "):\n",
    "    if not remaining_choices:\n",
    "        yield mapping\n",
    "        return\n",
    "\n",
    "    for choice in list(remaining_choices):\n",
    "        mapping.append(choice)\n",
    "        remaining_choices.remove(choice)\n",
    "        if valid_storage_order(mapping):\n",
    "            yield from recursive_order_storage_choices(mapping, nodes, remaining_choices)\n",
    "        mapping.pop()\n",
    "        remaining_choices.append(choice)\n",
    "\n",
    "def insert_temporal_loops(mapping: list[str]):\n",
    "    \n",
    "    seen_tensors = set()\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(mapping):\n",
    "        rank_vars = set(rank_variables)\n",
    "        for t in mapping[i].tensors():\n",
    "            if not (t._must_be_here and t in seen_tensors):\n",
    "                rank_vars -= tensor2rank_variables[t]\n",
    "        if i < len(mapping) - 1:\n",
    "            for t in mapping[i+1].tensors():\n",
    "                if not t._must_be_here:\n",
    "                    rank_vars &= tensor2rank_variables[t]\n",
    "        seen_tensors.update(mapping[i].tensors())\n",
    "        for t in tensors - seen_tensors:\n",
    "            rank_vars &= tensor2rank_variables[t]\n",
    "\n",
    "        mapping.insert(i+1, RankVariableSet(rank_vars))\n",
    "        i += 2\n",
    "    return mapping\n",
    "\n",
    "\n",
    "UNEVEN_CROSSES_SPATIAL_BOUNDARIES = False\n",
    "def insert_spatial_loops(mapping: list[str], nodes: list[Leaf]):\n",
    "    if not nodes:\n",
    "        yield mapping\n",
    "        return\n",
    "    node = nodes[0]\n",
    "    \n",
    "    if not node.spatial.fanout_X > 1 and not node.spatial.fanout_Y > 1:\n",
    "        yield from insert_spatial_loops(mapping, nodes[1:])\n",
    "        return\n",
    "    \n",
    "    # Insert fanout below all storage nodes above this one and above all storage\n",
    "    # nodes at or below this one\n",
    "    last_over, first_under = 0, len(mapping)\n",
    "    for i, m in enumerate_tensor_sets(mapping):\n",
    "        for t in m.tensors():\n",
    "            over = storage_order.index(t._storage_name) < storage_order.index(node.name)\n",
    "            under = not over\n",
    "            last_over = max(last_over, i) if over else last_over\n",
    "            first_under = min(first_under, i) if under else first_under\n",
    "\n",
    "    if last_over >= first_under:\n",
    "        if UNEVEN_CROSSES_SPATIAL_BOUNDARIES:\n",
    "            yield mapping\n",
    "        return\n",
    "    \n",
    "    insert_point = first_under - 1\n",
    "\n",
    "    tensors_not_seen_yet = set(tensors)\n",
    "    for i in range(insert_point):\n",
    "        if isinstance(mapping[i], TensorSet):\n",
    "            tensors_not_seen_yet -= set(mapping[i].tensors())\n",
    "    \n",
    "    loops = set(rank_variables)\n",
    "    for t in tensors_not_seen_yet:\n",
    "        loops &= tensor2rank_variables[t]\n",
    "    \n",
    "    if node.spatial.fanout_Y > 1:\n",
    "        mapping.insert(insert_point, RankVariableSet(loops, spatial=\"Y\", spatial_node=node.name))\n",
    "    if node.spatial.fanout_X > 1:\n",
    "        mapping.insert(insert_point, RankVariableSet(loops, spatial=\"X\", spatial_node=node.name))\n",
    "    yield from insert_spatial_loops(mapping, nodes[1:])\n",
    "    if node.spatial.fanout_X > 1:\n",
    "        mapping.pop(insert_point)\n",
    "    if node.spatial.fanout_Y > 1:\n",
    "        mapping.pop(insert_point)\n",
    "\n",
    "# If there are two back-to-back storages for the same tensor & the outer is\n",
    "# optional, then it is invalid.\n",
    "uneven_storages = [n for n in arch_nodes if n.constraints.storage.uneven]\n",
    "storage_choice_options = list(make_storage_choices_all_levels(arch_nodes, symbol_table))\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "mappings_count = 0\n",
    "main_memory = arch_nodes[0]\n",
    "n_mappings = 0\n",
    "\n",
    "# TODO: Check for ranks not in the mapping and put them at the bottom\n",
    "\n",
    "print(f\"Total mappings: {n_mappings}\")\n",
    "\n",
    "def make_mapping_nodes(mapping: list, symbol_table: dict[str, InvertibleSet]):\n",
    "    node2storage_constraint = {\n",
    "        n.name: n.constraints.storage._parse_non_keep_bypass(symbol_table) \n",
    "        for n in arch_nodes\n",
    "    }\n",
    "    node2spatial_X_constraint = {\n",
    "        n.name: n.constraints.get_spatial_constraint(for_X=True)._parse(symbol_table)\n",
    "        for n in arch_nodes\n",
    "    }\n",
    "    node2spatial_Y_constraint = {\n",
    "        n.name: n.constraints.get_spatial_constraint(for_Y=True)._parse(symbol_table)\n",
    "        for n in arch_nodes\n",
    "    }\n",
    "\n",
    "    mapping_nodes = []\n",
    "    for i, node in enumerate(mapping):\n",
    "        if isinstance(node, RankVariableSet):\n",
    "            if not node.spatial:\n",
    "                for r in node:\n",
    "                    mapping_nodes.append(TemporalMappingNode(rank=r))\n",
    "                    continue\n",
    "            else:\n",
    "                for r in node:\n",
    "                    mapping_nodes.append(SpatialMappingNode(rank=r, dimension=node.spatial))\n",
    "        elif isinstance(node, TensorSet):\n",
    "            for t in node:\n",
    "                mapping_nodes.append(StorageMappingNode(tensor_name=t[0].name))\n",
    "    return mapping_nodes\n",
    "\n",
    "from combinatorics.integer import integer_factorizations_to_n_parts\n",
    "import numpy as np\n",
    "\n",
    "def explore_tile_shapes(mapping_nodes: list[MappingNode], rank_variables: list[str]):\n",
    "    for n in mapping_nodes:\n",
    "        if isinstance(n, (SpatialMappingNode, TemporalMappingNode)):\n",
    "            if \n",
    "            \n",
    "    for rank_variable in rank_variables:\n",
    "        nodes = [\n",
    "            n for n in mapping_nodes\n",
    "            if (isinstance(n, (SpatialMappingNode, TemporalMappingNode)) and rank_variable == n.rank)\n",
    "        ]\n",
    "        size = rank_variable_to_size[rank_variable]\n",
    "        if not nodes and size != 1:\n",
    "            raise ValueError(f\"Rank variable {rank_variable} has no loops and size is not 1\")\n",
    "\n",
    "        choices = list(integer_factorizations_to_n_parts(size, len(nodes)))\n",
    "        for choice in choices:\n",
    "            for i, node in enumerate(nodes):\n",
    "                if isinstance(node, TemporalMappingNode):\n",
    "                    node.factor = choice[i]\n",
    "                elif isinstance(node, SpatialMappingNode):\n",
    "                    node.factor = choice[i]\n",
    "        \n",
    "\n",
    "\n",
    "for i, (storage_choices, symbol_table) in enumerate(make_storage_choices_all_levels(arch_nodes, symbol_table)):\n",
    "    print(f\"{i}/{len(storage_choice_options)}: {storage_choices}\")\n",
    "    flattened_storage_choices = []\n",
    "    mapping_base = [TensorSet(\n",
    "        (t, t._storage_name)\n",
    "        for t in storage_choices[main_memory.name]\n",
    "    )]\n",
    "    for t in mapping_base[-1]:\n",
    "        t[0]._must_be_here = True\n",
    "\n",
    "    for k, v in storage_choices.items():\n",
    "        if k != main_memory.name:\n",
    "            flattened_storage_choices.extend(TensorSet([(t, t._storage_name)]) for t in v)\n",
    "            for t in v:\n",
    "                t._must_be_here = False\n",
    "    for mapping in recursive_order_storage_choices(mapping_base, arch_nodes, flattened_storage_choices):\n",
    "        # print(mapping)\n",
    "        mapping = [x for x in mapping]\n",
    "        mapping = insert_temporal_loops(mapping)\n",
    "        for mapping2 in insert_spatial_loops(mapping, arch_nodes):\n",
    "            print(f\"\\t{mapping2}\")\n",
    "            explore_tile_shapes(make_mapping_nodes(mapping2, symbol_table), rank_variables)\n",
    "            n_mappings += 1\n",
    "\n",
    "# TODO: What if there are no loops?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
