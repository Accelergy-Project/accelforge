{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastfusion.frontend._set_parse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastfusion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_set_parse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InvertibleSet\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastfusion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01march\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Leaf, Memory\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastfusion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkload_spec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RankVariable, Tensor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastfusion.frontend._set_parse'"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import copy\n",
    "import io\n",
    "import itertools\n",
    "import pstats\n",
    "from typing import Iterator\n",
    "from fastfusion.frontend._set_parsing import InvertibleSet\n",
    "from fastfusion.frontend.arch import Leaf, Memory\n",
    "from fastfusion.frontend.workload.workload_spec import Tensor, RankVariable\n",
    "import fastfusion.frontend.mapping as mapping_import\n",
    "from fastfusion import Specification\n",
    "from fastfusion.mapper.FFM.exploration.single_einsum_mapper import iterate_mappings_constraints\n",
    "\n",
    "\n",
    "# # Example mapping node\n",
    "# type: \"temporal\"\n",
    "# rank: P\n",
    "# # Choose one of the following cases\n",
    "# # Case 1.a\n",
    "# tile_shape: 3   # will make tile shapes with shape 3\n",
    "# # Case 1.b\n",
    "# tile_shape: null # will create a sympy symbol to represent tile shape and use that\n",
    "# # Case 2.a\n",
    "# factor: 3       # will make 3 as evenly shaped possible tiles\n",
    "# # Case 2.b\n",
    "# factor: null    # will create a sympy symbol to represent the factor, then same as 2.a\n",
    "# # Case 3   (I'm only showing null from now on)\n",
    "# tile_pattern:\n",
    "#   stride: null\n",
    "#   initial_shape: null  # This will create tile like this [0, 1, ..., initial_shape - 1], [initial_shape, ..., initial_shape + stride - 1], [initial_shape + stride, ..., initial_shape + 2*stride - 1], ...\n",
    "# # Case 4\n",
    "# tile_pattern:\n",
    "#   stride: null\n",
    "#   shape: null      # This will create tile like this [0, 1, ..., shape-1], [stride, stride+1, ..., stride + shape-1], [2*stride, 2*stride + 1, ..., 2*stride + shape - 1], ...\n",
    "#         choices = list(integer_factorizations_to_n_parts(rank_size, len(loops)))\n",
    "\n",
    "# Tile shape constraint: Applies to all tensor(s) in a storage node for which that tile shape is relevant\n",
    "# Loop bound constraint: Only for spatial\n",
    "\n",
    "spec = Specification.from_yaml(\n",
    "    \"architecture/four_level.arch.yaml\",\n",
    "    \"workloads/mha_full_new.yaml\",\n",
    "    \"workloads/mha_full_new.renames.yaml\",\n",
    ")\n",
    "\n",
    "workload = spec.workload\n",
    "renames = spec.renames\n",
    "\n",
    "einsum_name = \"K\"\n",
    "einsum = workload.einsums[einsum_name]\n",
    "rank_variables = einsum.rank_variables\n",
    "tensors = einsum.tensors\n",
    "rank_variable_to_size = {r: 16 for r in rank_variables}\n",
    "\n",
    "# If there are two back-to-back storages for the same tensor & the outer is\n",
    "# optional, then it is invalid.\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "mappings_count = 0\n",
    "n_mappings = 0\n",
    "\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "for i, (mapping, constraints) in enumerate(iterate_mappings_constraints(spec, \"Q\")):\n",
    "    print(f\"{i}: {mapping.compact_string()}\")\n",
    "    for c in constraints:\n",
    "        print(c)\n",
    "\n",
    "# pr.disable()\n",
    "# s = io.StringIO()\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats('cumulative')\n",
    "# ps.print_stats(30)  # Print top 30 time-consuming functions\n",
    "# print(s.getvalue())\n",
    "\n",
    "# TODO: Check for ranks not in the mapping and put them at the bottom\n",
    "# TODO: What if there are no loops? \n",
    "# TODO: Set _must_exist for all backing storage nodes\n",
    "# TODO: Constraint attacher\n",
    "# TODO: Deprecate processors and BaseSpecification\n",
    "# TODO: Can't have tile size constraints on backing memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
