{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Fig.12 EyerissV2 Single-PE Reproduction\n",
    "\n",
    "Reproduces fig12 (EyerissV2 single-PE) from the micro22-sparseloop-artifact using AccelForge.\n",
    "\n",
    "**Workload:** MobileNet0.5-sparse, 8 layers (1x1 pointwise convolutions)\n",
    "**Architecture:** BackingStorage (DRAM) → iact_spad / weight_spad / psum_spad → reg → MAC\n",
    "**Sparse formats:** UOP+RLE with explicit per-rank flattened_rank_ids\n",
    "**Distribution:** uniform_only (hypergeometric density model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Add accelforge to path\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "from accelforge.frontend.spec import Spec\n",
    "from accelforge.model.main import evaluate_mapping\n",
    "\n",
    "FIG12_DIR = os.path.join(REPO_ROOT, 'tests', 'input_files', 'fig12')\n",
    "print(f'Using configs from: {FIG12_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Configuration Files\n",
    "\n",
    "The EyerissV2 PE has a 6-level hierarchy with separate scratchpads for inputs, weights, and partial sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['arch.yaml', 'sparse_SI_SW.yaml']:\n",
    "    with open(os.path.join(FIG12_DIR, name)) as f:\n",
    "        print(f'=== {name} ===')\n",
    "        print(f.read())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Layer Parameters\n",
    "\n",
    "All 8 layers are 1x1 pointwise convolutions (R=1, S=1, N=1, G=1) with varying M, E, F, C dimensions and input/weight densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer parameters from Sparseloop artifact (MobileNet0.5-sparse)\n",
    "LAYERS = {\n",
    "    'L07': {'M': 64,  'E': 32, 'F': 32, 'C': 64,  'd_I': 0.73, 'd_W': 0.52,\n",
    "            'BS_M': 8,  'BS_C': 8,  'psum_M': 8,  'psum_C': 8},\n",
    "    'L09': {'M': 128, 'E': 16, 'F': 16, 'C': 64,  'd_I': 0.86, 'd_W': 0.82,\n",
    "            'BS_M': 8,  'BS_C': 8,  'psum_M': 16, 'psum_C': 8},\n",
    "    'L13': {'M': 256, 'E': 8,  'F': 8,  'C': 128, 'd_I': 0.83, 'd_W': 0.64,\n",
    "            'BS_M': 16, 'BS_C': 16, 'psum_M': 16, 'psum_C': 8},\n",
    "    'L19': {'M': 256, 'E': 8,  'F': 8,  'C': 256, 'd_I': 0.61, 'd_W': 0.55,\n",
    "            'BS_M': 16, 'BS_C': 32, 'psum_M': 16, 'psum_C': 8},\n",
    "    'L21': {'M': 256, 'E': 8,  'F': 8,  'C': 256, 'd_I': 0.64, 'd_W': 0.60,\n",
    "            'BS_M': 16, 'BS_C': 32, 'psum_M': 16, 'psum_C': 8},\n",
    "    'L23': {'M': 256, 'E': 8,  'F': 8,  'C': 256, 'd_I': 0.61, 'd_W': 0.70,\n",
    "            'BS_M': 16, 'BS_C': 32, 'psum_M': 16, 'psum_C': 8},\n",
    "    'L25': {'M': 512, 'E': 4,  'F': 4,  'C': 256, 'd_I': 0.68, 'd_W': 0.65,\n",
    "            'BS_M': 32, 'BS_C': 32, 'psum_M': 16, 'psum_C': 8},\n",
    "    'L27': {'M': 512, 'E': 4,  'F': 4,  'C': 512, 'd_I': 0.58, 'd_W': 0.30,\n",
    "            'BS_M': 32, 'BS_C': 64, 'psum_M': 16, 'psum_C': 8},\n",
    "}\n",
    "\n",
    "df_layers = pd.DataFrame(LAYERS).T\n",
    "df_layers.index.name = 'Layer'\n",
    "display(df_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Programmatic Config Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "def make_workload_yaml(p):\n    \"\"\"Generate workload YAML string for a layer.\"\"\"\n    return f'''workload:\n  iteration_space_shape:\n    r: 0 <= r < 1\n    s: 0 <= s < 1\n    e: 0 <= e < {p['E']}\n    f: 0 <= f < {p['F']}\n    c: 0 <= c < {p['C']}\n    m: 0 <= m < {p['M']}\n    n: 0 <= n < 1\n    g: 0 <= g < 1\n  bits_per_value: {{~Outputs: 8, Outputs: 20}}\n  einsums:\n  - name: GroupedConv\n    tensor_accesses:\n    - name: Inputs\n      projection: [n, c, g, e, f]\n      density: {p['d_I']}\n    - name: Weights\n      projection: [c, m, g, r, s]\n      density: {p['d_W']}\n    - name: Outputs\n      projection: [n, g, m, f, e]\n      output: true\n'''\n\n\ndef make_mapping_yaml(p):\n    \"\"\"Generate mapping YAML string for a layer.\n\n    Mapping structure (top to bottom):\n    - BackingStorage: all tensors\n    - BS loops: M, C (outer), then weight_spad (Weights reuse across E,F)\n    - BS loops: F, E (inner pixel iteration)\n    - iact_spad (Inputs), psum_spad (Outputs)\n    - psum loop: C inner\n    - reg (Inputs, reused across M inner)\n    - psum loop: M inner\n    - Compute\n    \"\"\"\n    M_inner = p['M'] // p['BS_M']\n    C_inner = p['C'] // p['BS_C']\n    return f'''mapping:\n  nodes:\n  - !Storage {{tensors: [Inputs, Weights, Outputs], component: BackingStorage}}\n  - !Temporal {{rank_variable: m, tile_shape: {M_inner}}}\n  - !Temporal {{rank_variable: c, tile_shape: {C_inner}}}\n  - !Storage {{tensors: [Weights], component: weight_spad}}\n  - !Temporal {{rank_variable: f, tile_shape: 1}}\n  - !Temporal {{rank_variable: e, tile_shape: 1}}\n  - !Storage {{tensors: [Inputs], component: iact_spad}}\n  - !Storage {{tensors: [Outputs], component: psum_spad}}\n  - !Temporal {{rank_variable: c, tile_shape: 1}}\n  - !Storage {{tensors: [Inputs], component: reg}}\n  - !Temporal {{rank_variable: m, tile_shape: 1}}\n  - !Compute {{einsum: GroupedConv, component: MAC}}\n'''"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "def run_layer(layer_name, layer_params):\n    \"\"\"Run a single layer through AccelForge and return results.\"\"\"\n    workload_yaml = make_workload_yaml(layer_params)\n    mapping_yaml = make_mapping_yaml(layer_params)\n\n    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as wf:\n        wf.write(workload_yaml)\n        workload_path = wf.name\n    with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as mf:\n        mf.write(mapping_yaml)\n        mapping_path = mf.name\n\n    try:\n        spec = Spec.from_yaml(\n            os.path.join(FIG12_DIR, 'arch.yaml'),\n            workload_path,\n            mapping_path,\n            os.path.join(FIG12_DIR, 'sparse_SI_SW.yaml'),\n        )\n        result = evaluate_mapping(spec)\n\n        energy = float(result.data['Total<SEP>energy'].iloc[0])\n        latency = float(result.data['Total<SEP>latency'].iloc[0])\n\n        # Extract per-component energy\n        comp_energy = {}\n        for col in result.data.columns:\n            if '<SEP>energy<SEP>' in col:\n                parts = col.split('<SEP>')\n                comp = parts[2]  # component name\n                e = float(result.data[col].iloc[0])\n                comp_energy[comp] = comp_energy.get(comp, 0.0) + e\n\n        return {\n            'energy_pJ': energy,\n            'energy_uJ': energy / 1e6,\n            'cycles': latency,\n            'comp_energy': comp_energy,\n            'result': result,\n        }\n    finally:\n        os.unlink(workload_path)\n        os.unlink(mapping_path)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Run L07 (Detailed Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run L07 using static YAML files\n",
    "spec_L07 = Spec.from_yaml(\n",
    "    os.path.join(FIG12_DIR, 'arch.yaml'),\n",
    "    os.path.join(FIG12_DIR, 'workload_L07.yaml'),\n",
    "    os.path.join(FIG12_DIR, 'mapping_L07.yaml'),\n",
    "    os.path.join(FIG12_DIR, 'sparse_SI_SW.yaml'),\n",
    ")\n",
    "result_L07 = evaluate_mapping(spec_L07)\n",
    "\n",
    "# Show all non-zero action counts\n",
    "print('L07 Action Counts:')\n",
    "for col in sorted(result_L07.data.columns):\n",
    "    val = result_L07.data[col].iloc[0]\n",
    "    if 'action' in col and val != 0 and 'format' not in col:\n",
    "        name = col.replace('GroupedConv<SEP>action<SEP>', '')\n",
    "        print(f'  {name}: {val:,.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L07 per-component energy comparison\n",
    "SL_L07 = {\n",
    "    'MAC': 919355, 'reg': 372019, 'psum_spad': 1238919,\n",
    "    'weight_spad': 2247877, 'iact_spad': 213850, 'BackingStorage': 0,\n",
    "}\n",
    "\n",
    "print(f'{\"Component\":>15} | {\"AccelForge (pJ)\":>15} | {\"Sparseloop (pJ)\":>15} | {\"Delta %\":>8}')\n",
    "print('-' * 65)\n",
    "\n",
    "af_total = 0\n",
    "for comp in ['MAC', 'reg', 'psum_spad', 'weight_spad', 'iact_spad', 'BackingStorage']:\n",
    "    af_e = 0\n",
    "    for col in result_L07.data.columns:\n",
    "        if f'energy<SEP>{comp}<SEP>' in col or f'energy<SEP>{comp}' in col:\n",
    "            if '<SEP>energy<SEP>' in col:\n",
    "                af_e += float(result_L07.data[col].iloc[0])\n",
    "    af_total += af_e\n",
    "    sl_e = SL_L07[comp]\n",
    "    delta = ((af_e - sl_e) / sl_e * 100) if sl_e > 0 else 0\n",
    "    print(f'{comp:>15} | {af_e:>15,.0f} | {sl_e:>15,.0f} | {delta:>+7.1f}%')\n",
    "\n",
    "total_energy = float(result_L07.data['Total<SEP>energy'].iloc[0])\n",
    "total_latency = float(result_L07.data['Total<SEP>latency'].iloc[0])\n",
    "sl_total = sum(SL_L07.values())\n",
    "sl_cycles = 1592245\n",
    "print('-' * 65)\n",
    "print(f'{\"Total\":>15} | {total_energy:>15,.0f} | {sl_total:>15,.0f} | {(total_energy-sl_total)/sl_total*100:>+7.1f}%')\n",
    "print(f'{\"Cycles\":>15} | {total_latency:>15,.0f} | {sl_cycles:>15,.0f} | {(total_latency-sl_cycles)/sl_cycles*100:>+7.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Run All 8 Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "# Sparseloop ground truth (uniform_only, exact pJ from stats files)\nSL_GROUND_TRUTH = {\n    'L07': {'cycles': 1592245, 'energy_pJ': 4992020},\n    'L09': {'cycles': 1479114, 'energy_pJ': 3757580},\n    'L13': {'cycles': 1114139, 'energy_pJ': 2996420},\n    'L19': {'cycles': 1407304, 'energy_pJ': 4311730},\n    'L21': {'cycles': 1610668, 'energy_pJ': 4764760},\n    'L23': {'cycles': 1791135, 'energy_pJ': 5233700},\n    'L25': {'cycles': 927185,  'energy_pJ': 2713340},\n    'L27': {'cycles': 729915,  'energy_pJ': 2761280},\n}\n\nresults = {}\nfor name, params in LAYERS.items():\n    print(f'Running {name}...', end=' ')\n    try:\n        results[name] = run_layer(name, params)\n        print(f'OK (energy={results[name][\"energy_uJ\"]:.2f} uJ, cycles={results[name][\"cycles\"]:,.0f})')\n    except Exception as e:\n        print(f'FAILED: {e}')\n        results[name] = None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "# Comparison table\nrows = []\nfor name in LAYERS:\n    sl = SL_GROUND_TRUTH[name]\n    af = results.get(name)\n    if af is None:\n        rows.append({\n            'Layer': name, 'AF Cycles': 'FAILED', 'SL Cycles': sl['cycles'],\n            'AF Energy (uJ)': 'FAILED', 'SL Energy (uJ)': f\"{sl['energy_pJ']/1e6:.2f}\",\n        })\n        continue\n    sl_energy_uJ = sl['energy_pJ'] / 1e6\n    rows.append({\n        'Layer': name,\n        'AF Cycles': f\"{af['cycles']:,.0f}\",\n        'SL Cycles': f\"{sl['cycles']:,}\",\n        'Cycle Delta': f\"{(af['cycles'] - sl['cycles']) / sl['cycles'] * 100:+.1f}%\",\n        'AF Energy (uJ)': f\"{af['energy_uJ']:.2f}\",\n        'SL Energy (uJ)': f\"{sl_energy_uJ:.2f}\",\n        'Energy Delta': f\"{(af['energy_uJ'] - sl_energy_uJ) / sl_energy_uJ * 100:+.1f}%\",\n    })\n\ndf_comparison = pd.DataFrame(rows)\ndisplay(df_comparison)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 6. Energy Breakdown Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\nlayer_names = [n for n in LAYERS if results.get(n) is not None]\naf_energy = [results[n]['energy_uJ'] for n in layer_names]\nsl_energy = [SL_GROUND_TRUTH[n]['energy_pJ'] / 1e6 for n in layer_names]\n\nx = np.arange(len(layer_names))\nwidth = 0.35\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Energy comparison\nax1.bar(x - width/2, af_energy, width, label='AccelForge', color='tab:blue')\nax1.bar(x + width/2, sl_energy, width, label='Sparseloop', color='tab:orange')\nax1.set_xlabel('Layer')\nax1.set_ylabel('Energy (uJ)')\nax1.set_title('Per-Layer Energy')\nax1.set_xticks(x)\nax1.set_xticklabels(layer_names)\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Cycles comparison\naf_cycles = [results[n]['cycles'] for n in layer_names]\nsl_cycles = [SL_GROUND_TRUTH[n]['cycles'] for n in layer_names]\n\nax2.bar(x - width/2, af_cycles, width, label='AccelForge', color='tab:blue')\nax2.bar(x + width/2, sl_cycles, width, label='Sparseloop', color='tab:orange')\nax2.set_xlabel('Layer')\nax2.set_ylabel('Cycles')\nax2.set_title('Per-Layer Cycles')\nax2.set_xticks(x)\nax2.set_xticklabels(layer_names)\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "## 7. Results Summary\n\n### Total Energy and Cycles (all 8 layers)\n\n| Metric | Range | Notes |\n|--------|-------|-------|\n| **Energy** | -0.2% to +0.6% | All layers within 0.6% of Sparseloop |\n| **Cycles** | -0.0% | Near-perfect match across all layers |\n\n### L07 Per-Component Accuracy\n\nL07 is the reference layer with verified Sparseloop per-component energy from stats files.\n\n| Component | Delta | Notes |\n|-----------|-------|-------|\n| weight_spad | -0.0% | Per-element packing matches SL |\n| reg | -0.0% | metadata_storage_width=4 from arch |\n| iact_spad | +0.3% | UOP trivial dim fix (R=1) |\n| psum_spad | -1.8% | SL uses data-delta-dependent ERT |\n| MAC | +2.2% | Format-eliminated iterations counted as skipped |\n| **Total** | **-0.02%** | |\n\n### Key Fixes Applied (Phase 16)\n\n1. **metadata_storage_width from arch**: Falls back to `metadata_read` action's\n   `bits_per_action` (4 for iact_spad/reg, 8 for weight_spad) when sparse YAML\n   doesn't specify it. Previously defaulted to data read width, over-counting metadata.\n\n2. **Per-element packing**: SRAM words pack whole elements, not bit-streams.\n   `ceil(count / floor(msw / word_bits))` instead of `ceil(total_bits / msw)`.\n   Critical for UOP 7-bit payload in 8-bit SRAM (589,824 vs 516,096 words).\n\n3. **UOP trivial dimension**: `fiber_shape <= 1` (e.g. R=1) produces 0 payload.\n   Sparseloop reports 0 accesses for UOP on trivial ranks.\n\n### Known Remaining Model Differences\n\n1. **psum_spad ERT** (~1.8%): Sparseloop uses (addr_delta, data_delta)-dependent\n   energy. AccelForge uses single average value (0.33633 pJ).\n\n2. **MAC compute classification** (~2.2%): AccelForge counts format-eliminated\n   iterations as `skipped_compute` (0.01798 pJ each). Sparseloop may classify\n   some as zero-energy.\n\n3. **Cycle rounding** (<0.03%): Hypergeometric probability rounding differences."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}